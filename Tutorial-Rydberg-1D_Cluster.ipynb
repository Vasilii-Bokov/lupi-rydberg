{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e162833-e2d2-45a6-87dc-7ef80afba9c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:48:04.795813: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759243685.002110   91989 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759243685.125760   91989 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1759243686.160695   91989 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759243686.160744   91989 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759243686.160750   91989 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759243686.160754   91989 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from time import time\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "from src.models.mlp import MLP\n",
    "from src.eval import RydbergEvaluator\n",
    "from src.eval.eval_rydberg import est_density_from_z_measurements,determine_phase_1D,est_order_param_1D,phase2img,est_phase_diagram,est_order_param_1D_fourier_from_measurements,est_order_param_1D_fourier,est_order_param_1D_from_measurements\n",
    "from src.data.loading.dataset_rydberg import RydbergDataset,unif_sample_on_grid\n",
    "# Transformer\n",
    "import argparse\n",
    "from constants import *\n",
    "from src.training.rydberg_trainers import RydbergConditionalTransformerTrainer\n",
    "from src.models.transformer import init_conditional_transformer\n",
    "from src.models.mlp import MLP\n",
    "\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm,trange\n",
    "import os\n",
    "\n",
    "from src.utils import plot_phase_diagram\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87b3eef0-667a-4656-bee5-a302630a695f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Here we define a base schedule -- \n",
    "base_time = 3.5\n",
    "ts = np.array([0,0.2,base_time])\n",
    "omegas = np.array([0, 5, 5])\n",
    "deltas = np.array([-10, -10, 15])\n",
    "total_time = 15 # Total adiabatic evolution time of the Bloqade simulation\n",
    "# We propotionally lengthen the schedules for Omega and Delta by time_ratio = total_time/base_time\n",
    "time_ratio = total_time/base_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5252700",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 31 # number of Rydberg atoms in the 1D lattice\n",
    "\n",
    "dim=1 # dimension of the system\n",
    "ny = 1 # since we are working in 1D, this variable is fixed to 1\n",
    "nx = n_qubits # effectively, we are working on a 2D lattice of dimensions nx*ny, where nx=n_qubits and ny=1.\n",
    "z2_threshold=0.7 # threshold for the Z2 order parameter to determine a state is in Z2 phase\n",
    "z3_threshold = 0.6 # threshold for the Z3 order parameter to determine a state is in Z3 phase\n",
    "\n",
    "# We load simulation data for the lattice defined above with the adiabatic evolution scheduler preset above.\n",
    "folder = f'data/1D-Phase_{nx}/1D-Phase_{nx}/{float(np.round(total_time,2))}Âµs/'\n",
    "# folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "128640a1-a12c-48c3-a942-c322f543916d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# extra variables we want the conditional generative variable to condition on, except for \"nx\", \"ny\", \"interaction_range\".\n",
    "# detuning = Delta/Omega\n",
    "extra_variables = [\"detuning\",] \n",
    "meta_dataset = RydbergDataset(dim=dim,nx = nx, ny=ny, folder=folder,n_threads=1, \n",
    "                                         var_name='interaction_range',variables = extra_variables) \n",
    "meta_dataset.est_order_params()\n",
    "meta_dataset.info[\"phase\" ] = determine_phase_1D(meta_dataset.info[\"Z2\"], meta_dataset.info[\"Z3\"],z2_threshold=z2_threshold,\n",
    "                                                z3_threshold=z3_threshold\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4da8d082-38cd-439d-8cda-2a85f455b4cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "hue_order = ['Disordered','Z2','Z3']\n",
    "plot_df = meta_dataset.info.copy()\n",
    "plot_df = plot_df.loc[(plot_df['detuning'] >=-1) & (plot_df['interaction_range'] <= 2.8) & (plot_df['interaction_range'] > 1)]\n",
    "# fig = plot_phase_diagram(plot_df,title=f\"1D Lattice of {n_qubits} Rydberg Atoms: Phase Diagram\",hue_order = hue_order,\n",
    "#                         legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ce98876-ddc0-4906-b433-04ea3e77d4fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_train_set(meta_dataset, df=None, n_measurements:int = -1, x_bins=10,y_bins=10):\n",
    "    train_set = {}\n",
    "    if df is None: df = meta_dataset.info\n",
    "    train_idxes, train_df = unif_sample_on_grid(df.copy(),x_bins=x_bins,y_bins=y_bins)#,x_range=(0.4,1.78),y_range=(1.4,2.4))\n",
    "    # train_idxes = plot_df.index.values\n",
    "    train_keys = meta_dataset.keys[train_idxes]\n",
    "    train_set.update(meta_dataset.prepare_train_set(train_keys,n_measurements=n_measurements))\n",
    "    return train_set, train_idxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36eea258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide to load a pretrained model or train from scratch\n",
    "load_pretrained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c41f2725-555e-4986-ac74-fe125952f40a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if load_pretrained:\n",
    "    # If loading a pretrained model, we need to also load the training set that \n",
    "    # it was trained on (specified by sampled indices of the meta_dataset.info DataFrame)\n",
    "    train_idxes = np.load('logs/rydberg_1D/train_idxes.npy')\n",
    "    train_set = pickle.load(open('logs/rydberg_1D/train_set.pkl','rb'))\n",
    "else:\n",
    "    # If train from scratch, we sample training data from the phase diagram specified by plot_df\n",
    "    train_set, train_idxes = prepare_train_set(meta_dataset,df=plot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c9e3961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# This will consistently give you the same ordering\n",
    "train_set_keys = list(train_set.keys())\n",
    "train_set_values = list(train_set.values())\n",
    "\n",
    "# Select N random indices\n",
    "N = 20\n",
    "selected_indices = random.sample(range(len(train_set_keys)), N)\n",
    "\n",
    "# These will correspond to the same positions\n",
    "selected_dict_items = {train_set_keys[i]: train_set[train_set_keys[i]] for i in selected_indices}\n",
    "selected_array_items = [train_idxes[i] for i in selected_indices]\n",
    "\n",
    "train_set = selected_dict_items\n",
    "train_idxes = selected_array_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4812613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to save this training set, you can un-comment the following lines:\n",
    "# Create all necessary directories\n",
    "output_dir = f'logs/rydberg_1D/{N}'\n",
    "os.makedirs(output_dir, exist_ok=True)  # exist_ok=True prevents error if dir exists\n",
    "\n",
    "\n",
    "np.save(f'logs/rydberg_1D/{N}/train_idxes.npy',train_idxes)\n",
    "pickle.dump(train_set, open(f'logs/rydberg_1D/{N}/train_set.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6456977d-eeec-4491-b06a-21214cf8235a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train a Conditional Generative Model\n",
    "\n",
    "We first define some hyperparameters as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82c67731-51f4-4880-aa48-c16f8e530ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(args=[]):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data-dir', type=str, default='logs/rydberg/debug/')\n",
    "    parser.add_argument('--dim',type=int,default=1)\n",
    "    parser.add_argument('--nx',type=int,default=19)\n",
    "    parser.add_argument('--ny',type=int,default=1)\n",
    "    parser.add_argument('--total_time',type=float,default=6)\n",
    "    parser.add_argument('--tf-arch', type=str, default='transformer_l4_d128_h4')\n",
    "    parser.add_argument('--train-id', type=str, default=\"debug\")\n",
    "    parser.add_argument('--reps', type=int, default=1)\n",
    "    parser.add_argument('--ns', type=int, default=800, help='number of samples per hamiltonian')\n",
    "    parser.add_argument('--iterations', type=int, default=50000, help=\"training iterations\")\n",
    "    parser.add_argument('--eval-every', type=int, default=100)\n",
    "    parser.add_argument('--eval-samples', type=int, default=10000, help='number of generated samples for evaluation')\n",
    "    parser.add_argument('--k', type=int, default=1, help='number of buckets for median of means estimation')\n",
    "    parser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')\n",
    "    parser.add_argument('--verbose', type=int, default=1, choices=[0, 1])\n",
    "    parser.add_argument('--epoch-mode', type=int, default=1, choices=[0, 1])\n",
    "    parser.add_argument('--condition-mode', type=int, default=0, choices=[0, 1])\n",
    "    parser.add_argument('--seed', type=int, default=None)\n",
    "    return parser.parse_args(args)\n",
    "\n",
    "def get_hyperparams(**kwargs):\n",
    "    hparams = argparse.Namespace(\n",
    "        lr=1e-3,\n",
    "        wd=0,\n",
    "        bs=512,\n",
    "        dropout=0.0,\n",
    "        lr_scheduler=WARMUP_COSINE_SCHEDULER,\n",
    "        warmup_frac=0.,\n",
    "        final_lr=1e-7,\n",
    "        smoothing=0.0,\n",
    "        use_padding=0,\n",
    "        val_frac=0.25,\n",
    "        cattn=0\n",
    "    )\n",
    "\n",
    "    for k, v in kwargs.items():\n",
    "        setattr(hparams, k, v)\n",
    "\n",
    "    return hparams\n",
    "args = parse_args()\n",
    "hparams = get_hyperparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5945e73-bbf0-4b25-8214-f68f42d40331",
   "metadata": {},
   "source": [
    "### Select Device (GPU/CPU)\n",
    "`gpu_idx < 0`: Use CPU\n",
    "\n",
    "`gpu_idx > 0`: Use NVIDIA GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54a933f0-b42e-48cd-814e-c1188ad8a7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:2\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "gpu_idx = 2\n",
    "device = torch.device(f\"cuda:{gpu_idx}\") if gpu_idx >= 0 else torch.device('cpu')\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e26e8b1-7ae4-454f-b6ec-dbff4d7dec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outcomes = 2 # for rydberg systems\n",
    "n_vars = len(list(train_set.keys())[0])\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(seed=args.seed)\n",
    "# setup transformer\n",
    "d_model = TF_ARCHS[args.tf_arch]['d_model']\n",
    "n_head = TF_ARCHS[args.tf_arch]['n_head']\n",
    "n_layers = TF_ARCHS[args.tf_arch]['n_layers']\n",
    "assert d_model % n_head == 0, 'd_model must be integer multiple of n_head!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68222403-40b4-4318-b583-93366f724e0a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We construct a MLP (fully-connected net) as the encoder and a transformer as the generative model, and then train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d218e16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoder \u001b[38;5;241m=\u001b[39m \u001b[43mMLP\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m              \u001b[49m\u001b[43mn_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mELU\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m              \u001b[49m\u001b[43minput_layer_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m              \u001b[49m\u001b[43moutput_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m             \u001b[49m\u001b[43moutput_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m transformer \u001b[38;5;241m=\u001b[39m init_conditional_transformer(\n\u001b[1;32m      8\u001b[0m         n_outcomes\u001b[38;5;241m=\u001b[39mnum_outcomes,\n\u001b[1;32m      9\u001b[0m         encoder\u001b[38;5;241m=\u001b[39mencoder,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m         use_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m#***\u001b[39;00m\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/research/generative-quantum-states-main/src/models/mlp.py:32\u001b[0m, in \u001b[0;36mMLP.__init__\u001b[0;34m(self, input_size, output_size, n_layers, hidden_size, activation, input_layer_norm, output_batch_size, device, output_factor)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_factor \u001b[38;5;241m=\u001b[39m output_factor\n",
      "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.12/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.12/site-packages/torch/cuda/__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "encoder = MLP(input_size=n_vars, output_size=d_model, \n",
    "              n_layers=1, hidden_size=128, activation='ELU', \n",
    "              input_layer_norm=False,\n",
    "              output_batch_size=None, device=device,\n",
    "             output_factor=1.)\n",
    "\n",
    "transformer = init_conditional_transformer(\n",
    "        n_outcomes=num_outcomes,\n",
    "        encoder=encoder,\n",
    "        n_layers=n_layers,\n",
    "        d_model=d_model,\n",
    "        d_ff=4 * d_model,\n",
    "        n_heads=n_head,\n",
    "        dropout=hparams.dropout,\n",
    "        version=hparams.use_padding,\n",
    "        use_prompt=False, #***\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2f6592a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m RydbergConditionalTransformerTrainer(model\u001b[38;5;241m=\u001b[39m\u001b[43mtransformer\u001b[49m,\n\u001b[1;32m      2\u001b[0m                                   train_dataset\u001b[38;5;241m=\u001b[39mtrain_set,\n\u001b[1;32m      3\u001b[0m                                   test_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m                                   iterations\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39miterations,\n\u001b[1;32m      5\u001b[0m                                   lr\u001b[38;5;241m=\u001b[39mhparams\u001b[38;5;241m.\u001b[39mlr,\n\u001b[1;32m      6\u001b[0m                                   final_lr\u001b[38;5;241m=\u001b[39mhparams\u001b[38;5;241m.\u001b[39mfinal_lr,\n\u001b[1;32m      7\u001b[0m                                   lr_scheduler\u001b[38;5;241m=\u001b[39mhparams\u001b[38;5;241m.\u001b[39mlr_scheduler,\n\u001b[1;32m      8\u001b[0m                                   warmup_frac\u001b[38;5;241m=\u001b[39mhparams\u001b[38;5;241m.\u001b[39mwarmup_frac,\n\u001b[1;32m      9\u001b[0m                                   weight_decay\u001b[38;5;241m=\u001b[39mhparams\u001b[38;5;241m.\u001b[39mwd,\n\u001b[1;32m     10\u001b[0m                                   batch_size\u001b[38;5;241m=\u001b[39mhparams\u001b[38;5;241m.\u001b[39mbs,\n\u001b[1;32m     11\u001b[0m                                   rng\u001b[38;5;241m=\u001b[39mrng,\n\u001b[1;32m     12\u001b[0m                                   smoothing\u001b[38;5;241m=\u001b[39mhparams\u001b[38;5;241m.\u001b[39msmoothing,\n\u001b[1;32m     13\u001b[0m                                   eval_every\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39meval_every,\n\u001b[1;32m     14\u001b[0m                                   transfomer_version\u001b[38;5;241m=\u001b[39mhparams\u001b[38;5;241m.\u001b[39muse_padding,\n\u001b[1;32m     15\u001b[0m                                   device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     16\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer_nq-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_qubits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_iter-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39miterations\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1000\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining iterations:\u001b[39m\u001b[38;5;124m'\u001b[39m, args\u001b[38;5;241m.\u001b[39miterations)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transformer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = RydbergConditionalTransformerTrainer(model=transformer,\n",
    "                                  train_dataset=train_set,\n",
    "                                  test_dataset=None,\n",
    "                                  iterations=args.iterations,\n",
    "                                  lr=hparams.lr,\n",
    "                                  final_lr=hparams.final_lr,\n",
    "                                  lr_scheduler=hparams.lr_scheduler,\n",
    "                                  warmup_frac=hparams.warmup_frac,\n",
    "                                  weight_decay=hparams.wd,\n",
    "                                  batch_size=hparams.bs,\n",
    "                                  rng=rng,\n",
    "                                  smoothing=hparams.smoothing,\n",
    "                                  eval_every=args.eval_every,\n",
    "                                  transfomer_version=hparams.use_padding,\n",
    "                                  device=device)\n",
    "model_name = f'transformer_nq-{n_qubits}_iter-{args.iterations//1000}k'\n",
    "print('Training iterations:', args.iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f6b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "\n",
    "# Create all necessary directories\n",
    "output_dir = f'logs/rydberg_1D/{N}'\n",
    "os.makedirs(output_dir, exist_ok=True)  # exist_ok=True prevents error if dir exists\n",
    "\n",
    "# Now save the model\n",
    "model_path = f'{output_dir}/{model_name}.pth'\n",
    "torch.save(transformer, model_path)\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "# torch.save(transformer,f'logs/rydberg_1D/{N}/{model_name}.pth') # You can save the trained model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
